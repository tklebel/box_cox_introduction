---
title: "Box-Cox Transformationen"
subtitle: "Untertitel???"
author: "Thomas Klebel & Daniel Kreimer"
date: "2020-05-26"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: zenburn
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(dev = "svg")
knitr::opts_knit$set(global.par = TRUE)
par(mar = c(2, 2, 1.5, 2))


library(tidyverse)
library(gganimate)
theme_set(theme_bw())

library(car)
data(Salaries)
```



# Motivation

Verletzung der **Annahme B4** im Regressionsmodell: 

- B4: "(Normalverteilung) Die Störgrößen $u_t$ sind normalverteilt."

```{r, echo=FALSE, fig.height=4.5, fig.width=8}
ggplot(Salaries, aes(salary)) +
  geom_histogram(bins = 25) +
  labs(x = NULL)
```



---
# Box-Cox-Modell als Heuristik


> We shall choose $\lambda$ partly in the light of the information provided by the data and partly from general considerations of simplicity, ease of interpretation, etc. For instance, it would be quite possible for the formal analysis to show that say $\sqrt{y}$ is the best scale for normality and constancy of variance, but for us to decide that there are compelling arguments of ease of interpretation for working say with $log(y)$. [...] the method developed below for finding a transformation is useful as a guide, but is, of course, not to be followed blindly. (p.213)

Ziel der Transformation:
> The [Box-Cox-Transformation] seeks to achieve simultaneously a model with (a) simple structure for the expectations, (b) constant variance and (c) normal distributions. (p. 226)

---

# Beispiel: Einkommen von Uni-Professoren

Datensatz 'Salaries' (aus dem Package 'car')
``` {r}
library(car)
data(Salaries)

```


```{r}
head(Salaries)
```


---

# Modellspezifikation

```{r}
model <- lm(salary ~ rank + yrs.service + yrs.since.phd +
              discipline, data = Salaries)
broom::tidy(summary(model))

broom::glance(summary(model))
```

---
# Prüfung der NV-Annahme der Residuen
QQ-Plot: visualisiert die theoretische Position der Residuen, unter der Annahme der Normalverteilung, und stellt diese als Gerade dar. Darauf werden die beobachteten Residuen des Modells gelegt. 



```{r, echo=TRUE, fig.height=3.7, fig.width=6}
plot(model, 2)
```


---
class: center, middle, inverse

# Mathematische Grundlagen der Transformation


---



# Grundlagen der Transformation

**Box-Cox-Modell**:

$$Y_i^{(\lambda)} = \alpha + \beta_1X_{i1} + \cdots + \beta_kX_{ik} + \epsilon_i$$

mit $\epsilon \sim N(0, \sigma_\epsilon^2)$ und


$$Y_i^{(\lambda)} =
    \begin{cases}
      \frac{Y_i^{\lambda} - 1}{\lambda}  & \text{wenn}\ \lambda \neq 0 \\
       \\
      log(Y_i) & \text{wenn}\ \lambda = 0
    \end{cases}$$

Bedingung: Alle Y-Werte müssen positiv sein. 

---

# Vergleich der Verteilungen (1)

```{r, echo=FALSE}
set.seed(202005)
```


```{r}
# Simluierte Werte
df <- data.frame(y = rchisq(n = 500, df = 8))
```



```{r, echo=FALSE, fig.width=8, fig.height=4}
ggplot(df, aes(y)) +
  geom_density() + 
  # geom_freqpoly(bins = 40) +
  theme_bw()
```



---

# Vergleich der Verteilungen (2)
![](test.gif)



---
# Berechnung von $\lambda$ (1)

```{r}
df <- df %>% 
  mutate(x = y + rnorm(500, mean = 0, sd = 8))
```

```{r, echo=FALSE, fig.width=7, fig.height=4, message=FALSE}
corr <- round(cor(df$x, df$y), 2)
label <- sprintf("~ rho == %0.2f", corr)

ggplot(df, aes(x, y)) +
  geom_point() +
  geom_smooth() +
  annotate("text", x = -10, y = 15, parse = TRUE, size = 5,
           label = label)
```

---
# Berechnung von $\lambda$ (2)

```{r}
m1 <- lm(y ~ x, data = df)
summary(m1)
```


---
# Berechnung von $\lambda$ (3)

`car::boxCox` berechnet $\lambda$ via Maximum-Likelihood-Schätzung (basierend auf den Residuen)
```{r, echo=FALSE}
par(mar = c(3, 4, 1, 2))
```

```{r, fig.width=6, fig.height=2.5}
bc <- car::boxCox(m1)
best.lambda <- bc$x[which(bc$y == max(bc$y))]
best.lambda
```





---
# Neues Modell mit Transformation (1)

```{r}
transform_box_cox <- function(y, lambda) {
  (y ^ lambda - 1)/lambda
}

df <- mutate(df, y_trans = transform_box_cox(y, best.lambda))
```

```{r, echo=FALSE, fig.height=3.5, fig.width=7}
df %>% 
  pivot_longer(c(y, y_trans)) %>% 
  ggplot(aes(value, fill = name)) +
  geom_density(alpha = .5) +
  labs(x = NULL, fill = NULL) +
  scale_fill_brewer(palette = "Set1") +
  theme(legend.position = c(.8, .8))
```


---
# Neues Modell mit Transformation (2)

```{r}
m2 <- lm(y_trans ~ x, data = df)

```

```{r, echo=FALSE}
rbind(
  broom::glance(m1),
  broom::glance(m2)
) %>% 
  mutate(model = c("m1", "m2")) %>% 
  select(model, r.squared, sigma)
```


---
class: center, middle, inverse

# Fortsetzung praktisches Beispiel




---
# Transformieren der abhängigen Variable

```{r, fig.width=6, fig.height=2.5}
bc <- car::boxCox(model,plotit = FALSE)
(best.lambda <- bc$x[which(bc$y == max(bc$y))])

Salaries$salary_t <- transform_box_cox(Salaries$salary, best.lambda)
```

```{r, echo=FALSE, fig.height=3}
Salaries %>% 
  pivot_longer(starts_with("salary")) %>% 
  ggplot(aes(value)) +
  geom_freqpoly(bins = 12) +
  facet_wrap(~name, scales = "free_x", nrow = 1) +
  labs(x = NULL, y = NULL)
```

---
# Neues Modell

```{r}
new_model <- lm(salary_t ~ rank + yrs.service + yrs.since.phd + 
                  discipline, data = Salaries)
broom::tidy(summary(new_model))

broom::glance(summary(new_model))

```


---
# QQ-Plot
Verbesserte Normalverteilung der Residuen bei transformiertem Y. 
```{r, echo=FALSE}
par(mar = c(2, 2, 1.5, 2))
```

```{r, fig.width=6, fig.height=4}
plot(new_model, 2)
```


---
# Marginale Veränderung
```{r}
coef(new_model)[["yrs.service"]]
``` 


```{r, echo=FALSE}
expand_grid(
  rank = "AsstProf",
  discipline = "A", 
  yrs.since.phd = 10,
  yrs.service = 1:40
) %>% 
  broom::augment(new_model, newdata = .) %>% 
  ggplot(aes(yrs.service, .fitted)) +
  geom_line()


```




