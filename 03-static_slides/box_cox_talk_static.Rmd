---
title: "Box-Cox Transformationen"
author: "Thomas Klebel & Daniel Kreimer"
date: "2020-05-26"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: zenburn
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(dev = "svg")
knitr::opts_knit$set(global.par = TRUE)
par(mar = c(2, 2, 1.5, 2))


library(tidyverse)
library(ggtext)
theme_set(theme_bw())

library(car)
data(Salaries)
```


# Agenda

- Problemstellung anhand eines praktischen Beispiels
  - Regressionsmodell
  - QQ-Plot
- Grundlagen der Transformation
  - Berechnung von $\lambda$
  - Auswirkung auf die Residuen
  - Interpretation
- Anwendung der Transformation auf das praktische Beispiel



---
# Motivation

Verletzung der Normalverteilungsannahme im Regressionsmodell: 

- "Die Störgrößen $u_t$ sind normalverteilt." (von Auer 2005:413)

```{r, echo=FALSE, fig.height=4.5, fig.width=8}
ggplot(Salaries, aes(salary)) +
  geom_histogram(bins = 25) +
  labs(x = NULL)
```




---

# Beispiel: Einkommen von Uni-Professoren

Datensatz 'Salaries' (aus dem Package 'car')
``` {r}
library(car)
data(Salaries)

```


```{r}
head(Salaries)
```


---

# Modellspezifikation

```{r}
model <- lm(salary ~ rank + yrs.service + yrs.since.phd +
              discipline, data = Salaries)
broom::tidy(summary(model))

broom::glance(summary(model))
```

---
# Prüfung der NV-Annahme der Residuen
QQ-Plot: visualisiert die theoretische Position der Residuen, unter der Annahme der Normalverteilung, und stellt diese als Gerade dar. Darauf werden die beobachteten Residuen des Modells gelegt. 



```{r, echo=TRUE, fig.height=3.7, fig.width=6}
plot(model, 2)
```


---
class: center, middle, inverse

# Grundlagen der Transformation


---



# Grundlagen der Transformation

**Box-Cox-Modell**:

$$Y_i^{(\lambda)} = \alpha + \beta_1X_{i1} + \cdots + \beta_kX_{ik} + \epsilon_i$$

mit $\epsilon \sim N(0, \sigma_\epsilon^2)$ und


$$Y_i^{(\lambda)} =
    \begin{cases}
      \frac{Y_i^{\lambda} - 1}{\lambda}  & \text{wenn}\ \lambda \neq 0 \\
       \\
      log(Y_i) & \text{wenn}\ \lambda = 0
    \end{cases}$$

Bedingung: Alle Y-Werte müssen positiv sein. 

---

# Vergleich der Verteilungen (1)

```{r, echo=FALSE}
set.seed(202005)
```


```{r}
# Simluierte Werte
df <- data.frame(y = rchisq(n = 500, df = 5))
```



```{r, echo=FALSE, fig.width=8, fig.height=4}
ggplot(df, aes(y)) +
  geom_density() + 
  # geom_freqpoly(bins = 40) +
  theme_bw()
```



---

# Vergleich der Verteilungen (2)
```{r, echo=FALSE, fig.height=5, fig.width=8}
transform_box_cox <- function(y, lambda) {
  (y ^ lambda - 1)/lambda
}

df2 <- df %>%
  mutate(lambda = list(seq(-2, 2, by = .5))) %>%
  unnest(lambda) %>%
  mutate(y_trans = case_when(lambda == 0 ~ log(y),
                             TRUE ~ transform_box_cox(y, lambda)))

ggplot(df2, aes(y_trans)) +
  geom_density(fill = "#e41a1c", alpha = .5) +
  geom_density(aes(y), fill = "#377eb8", alpha = .5) +
  facet_wrap(~lambda, scales = "free_y") +
  coord_cartesian(xlim = c(0, 40)) +
  theme_bw() +
  theme(plot.subtitle = element_markdown()) +
  labs(title = "Transformation von Y in Abhängigkeit von Lambda",
       subtitle = "<span style='color:#377eb8'>Originale</span> vs. <span style='color:#e41a1c'>transformierte</span> Variable", x = NULL, y = "Dichte")
```




---
# Berechnung von $\lambda$ (1)

```{r}
df <- df %>% 
  mutate(x = y + rnorm(500, mean = 0, sd = 8))
```

```{r, echo=FALSE, fig.width=7, fig.height=4, message=FALSE}
corr <- round(cor(df$x, df$y), 2)
label <- sprintf("~ rho == %0.2f", corr)

ggplot(df, aes(x, y)) +
  geom_point() +
  geom_smooth() +
  annotate("text", x = -10, y = 15, parse = TRUE, size = 5,
           label = label)
```

---
# Berechnung von $\lambda$ (2)

```{r}
m1 <- lm(y ~ x, data = df)
```

```{r, fig.width=7, fig.height=4, echo=FALSE}
plot(m1, 2, caption = NA, main = "Modell 1 (m1)")
```



---
# Berechnung von $\lambda$ (3)

`car::boxCox` berechnet $\lambda$ via Maximum-Likelihood-Schätzung (basierend auf den Residuen)
```{r, echo=FALSE}
par(mar = c(3, 4, 1, 2))
```

```{r, fig.width=6, fig.height=2.5}
bc <- car::boxCox(m1)
best.lambda <- bc$x[which(bc$y == max(bc$y))]
best.lambda
```





---
# Neues Modell mit Transformation (1)

```{r}
transform_box_cox <- function(y, lambda) {
  (y ^ lambda - 1)/lambda
}

df <- mutate(df, y_trans = transform_box_cox(y, best.lambda))
```

```{r, echo=FALSE, fig.height=3.5, fig.width=7}
df %>% 
  pivot_longer(c(y, y_trans)) %>% 
  ggplot(aes(value, fill = name)) +
  geom_density(alpha = .5) +
  labs(x = NULL, fill = NULL) +
  scale_fill_manual(values = c(y = "#377eb8", y_trans = "#e41a1c")) +
  theme(legend.position = c(.8, .8))
```


---
# Neues Modell mit Transformation (2)

```{r}
m2 <- lm(y_trans ~ x, data = df)
```

```{r, echo=FALSE}
par(mar = c(2, 2, 1.5, 2))
```

.pull-left[
```{r, fig.width=4, fig.height=4, echo=FALSE}
plot(m1, 2, caption = NA, main = "Modell 1 (m1)")
```
]

.pull-right[
```{r, fig.width=4, fig.height=4, echo=FALSE}
plot(m2, 2, caption = NA, main = "Modell 2 (m2)")
```
]



---
# Interpretation

- Direkte Interpretation der Koeffizienten schwierig, außer für bekannte Fälle
wie $log(Y)$
- Alternativ: Vorhersage für plausible $X_i$ und Re-Transformierung der Vorhersage

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.height=4, fig.width=7}
pdata <- data.frame(x = 1:50) %>% 
  broom::augment(m2, newdata = .) %>% 
  mutate(.fitted_trans = (.fitted * best.lambda + 1)^(1/best.lambda),
         marginal_diff = lead(.fitted_trans) - .fitted_trans)

library(patchwork)
p1 <- pdata %>% 
  ggplot(aes(x, .fitted_trans)) +
  geom_line() +
  geom_point() 

p2 <- pdata %>% 
  ggplot(aes(x, marginal_diff)) +
  geom_line() +
  geom_point() +
  labs(y = "Marginale Veränderung in Y")

p1 + p2
```





---
class: center, middle, inverse

# Fortsetzung praktisches Beispiel

---
# Box-Cox-Modell als Heuristik



> We shall choose $\lambda$ partly in the light of the information provided by the data and partly from general considerations of simplicity, ease of interpretation, etc. For instance, it would be quite possible for the formal analysis to show that say $\sqrt{y}$ is the best scale for normality and constancy of variance, but for us to decide that there are compelling arguments of ease of interpretation for working say with $log(y)$. [...] the method developed below for finding a transformation is useful as a guide, but is, of course, not to be followed blindly. (Box and Cox 1964:213)


Box, G. E. P., and D. R. Cox. 1964. “An Analysis of Transformations.” Journal of the Royal Statistical Society. Series B (Methodological) 26 (2): 211–52.

---
# Transformieren der abhängigen Variable

```{r, fig.width=6, fig.height=2.5}
bc <- car::boxCox(model, plotit = FALSE)
(best.lambda <- bc$x[which(bc$y == max(bc$y))])

Salaries$salary_t <- transform_box_cox(Salaries$salary, best.lambda)
```

```{r, echo=FALSE, fig.height=3}
Salaries %>% 
  pivot_longer(starts_with("salary")) %>% 
  ggplot(aes(value)) +
  geom_freqpoly(bins = 12) +
  facet_wrap(~name, scales = "free_x", nrow = 1) +
  labs(x = NULL, y = NULL)
```

---
# Neues Modell

```{r}
new_model <- lm(salary_t ~ rank + yrs.service + yrs.since.phd + 
                  discipline, data = Salaries)
broom::tidy(summary(new_model))

broom::glance(summary(new_model))

```


---
# QQ-Plot
Verbesserte Normalverteilung der Residuen bei transformiertem Y. 
```{r, echo=FALSE}
par(mar = c(2, 2, 1.5, 2))
```

.pull-left[
```{r, fig.width=4, fig.height=4, echo=FALSE}
plot(model, 2, caption = NA, main = "Modell 1 (model)")
```
]

.pull-right[
```{r, fig.width=4, fig.height=4, echo=FALSE}
plot(new_model, 2, caption = NA, main = "Modell 2 (new_model)")
```
]




